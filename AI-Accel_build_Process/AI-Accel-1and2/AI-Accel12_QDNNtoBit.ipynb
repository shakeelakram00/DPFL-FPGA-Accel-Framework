{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/package/_directory_reader.py:17: UserWarning: Failed to initialize NumPy: No module named 'numpy.core._multiarray_umath' (Triggered internally at  /root/pytorch/torch/csrc/utils/tensor_numpy.cpp:68.)\n",
      "  _dtype_to_storage = {data_type(0).dtype: data_type for data_type in _storages}\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/benoitmartin88/pytorchtrainer.git\n",
    "\n",
    "!pip install torchsummary\n",
    "\n",
    "!pip install brevitas\n",
    "\n",
    "!pip install -U netron\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, SGD\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "# from torchsummary import summary\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from sklearn.utils import resample\n",
    "\n",
    "from torch.nn import Module, ModuleList, BatchNorm2d, MaxPool2d, BatchNorm1d, ReLU, Softmax, CrossEntropyLoss, Sequential, Dropout, Conv2d, Linear\n",
    "\n",
    "from brevitas.nn import QuantConv2d, QuantIdentity, QuantLinear, QuantReLU\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "from tensor_norm import TensorNorm\n",
    "from common import CommonWeightQuant, CommonActQuant\n",
    "\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.custom_op.registry import getCustomOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNV_OUT_CH_POOL = [(21, False), (21, True), (21, False)]#, (128, True), (256, False), (256, False)]\n",
    "INTERMEDIATE_FC_FEATURES = [(3549, 16), (16, 16)]\n",
    "LAST_FC_IN_FEATURES = 16\n",
    "LAST_FC_PER_OUT_CH_SCALING = False\n",
    "POOL_SIZE = 2\n",
    "KERNEL_SIZE = 6\n",
    "\n",
    "class CNV(Module):\n",
    "\n",
    "    def __init__(self, num_classes, weight_bit_width, act_bit_width, in_bit_width, in_ch):\n",
    "        super(CNV, self).__init__()\n",
    "\n",
    "        self.conv_features = ModuleList()\n",
    "        self.linear_features = ModuleList()\n",
    "\n",
    "        self.conv_features.append(QuantIdentity( # for Q1.7 input format\n",
    "            act_quant=CommonActQuant,\n",
    "            bit_width=in_bit_width,\n",
    "            min_val=- 1.0,\n",
    "            max_val=1.0 - 2.0 ** (-7),\n",
    "            narrow_range=False,\n",
    "            restrict_scaling_type=RestrictValueType.POWER_OF_TWO))\n",
    "\n",
    "        for out_ch, is_pool_enabled in CNV_OUT_CH_POOL:\n",
    "            self.conv_features.append(QuantConv2d(\n",
    "                kernel_size=KERNEL_SIZE,\n",
    "                in_channels=in_ch,\n",
    "                out_channels=out_ch,\n",
    "                bias=False,\n",
    "                padding=4,\n",
    "                weight_quant=CommonWeightQuant,\n",
    "                weight_bit_width=weight_bit_width))\n",
    "            in_ch = out_ch\n",
    "            #self.conv_features.append(BatchNorm2d(in_ch, eps=1e-4))\n",
    "            self.conv_features.append(QuantIdentity(\n",
    "                act_quant=CommonActQuant,\n",
    "                bit_width=act_bit_width))\n",
    "            if is_pool_enabled:\n",
    "                self.conv_features.append(MaxPool2d(kernel_size=2))\n",
    "\n",
    "        for in_features, out_features in INTERMEDIATE_FC_FEATURES:\n",
    "            self.linear_features.append(QuantLinear(\n",
    "                in_features=in_features,\n",
    "                out_features=out_features,\n",
    "                bias=False,\n",
    "                weight_quant=CommonWeightQuant,\n",
    "                weight_bit_width=weight_bit_width))\n",
    "            #self.linear_features.append(BatchNorm1d(out_features, eps=1e-4))\n",
    "            self.linear_features.append(QuantIdentity(\n",
    "                act_quant=CommonActQuant,\n",
    "                bit_width=act_bit_width))\n",
    "\n",
    "        self.linear_features.append(QuantLinear(\n",
    "            in_features=LAST_FC_IN_FEATURES,\n",
    "            out_features=num_classes,\n",
    "            bias=False,\n",
    "            weight_quant=CommonWeightQuant,\n",
    "            weight_bit_width=weight_bit_width))\n",
    "        self.linear_features.append(TensorNorm())\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, QuantConv2d) or isinstance(m, QuantLinear):\n",
    "                torch.nn.init.uniform_(m.weight.data, -1, 1)\n",
    "\n",
    "\n",
    "    def clip_weights(self, min_val, max_val):\n",
    "        for mod in self.conv_features:\n",
    "            if isinstance(mod, QuantConv2d):\n",
    "                mod.weight.data.clamp_(min_val, max_val)\n",
    "        for mod in self.linear_features:\n",
    "            if isinstance(mod, QuantLinear):\n",
    "                mod.weight.data.clamp_(min_val, max_val)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = 2.0 * x - torch.tensor([1.0], device=x.device)\n",
    "        for mod in self.conv_features:\n",
    "            x = mod(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        for mod in self.linear_features:\n",
    "            x = mod(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNV(num_classes=5, weight_bit_width=1, act_bit_width=1, in_bit_width=8, in_ch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Layer (type)                           Output Shape                    Param #\n",
      "--------------------------------------------------------------------------------\n",
      "  1 conv_features                     [21, 1, 6, 6]                      756\n",
      "  2 conv_features                     [21, 21, 6, 6]                   15876\n",
      "  3 conv_features                     [21, 21, 6, 6]                   15876\n",
      "  4 linear_features                   [16, 3549]                       56784\n",
      "  5 linear_features                   [16, 16]                           256\n",
      "  6 linear_features                   [5, 16]                             80\n",
      "  7 linear_features                   [1]                                  1\n",
      "  8 linear_features                   [1]                                  1\n",
      "_______________________________________________________________________________\n",
      "Total parameters = 89630\n",
      "Trainable parameters = 89630\n",
      "Non-trainable parameters = 0\n",
      "-------------------------------------------------------------------------------\n",
      "Input Size (MB): 0.0007476806640625\n",
      "Forward/Backward pass size (MB): 0.6838226318359375\n",
      "Param Size (MB): 0.34191131591796875\n",
      "Estimated Total Size (MB) : 1.0264816284179688\n"
     ]
    }
   ],
   "source": [
    "def print_summary(model):\n",
    "    total_params = 0\n",
    "    trainable_params = 0\n",
    "    non_trainable_params = 0\n",
    "\n",
    "    layer_num = 0\n",
    "    print(\"________________________________________________________________________________\")\n",
    "    print(\"Layer (type)                           Output Shape                    Param #\")\n",
    "    print(\"--------------------------------------------------------------------------------\")\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "        else:\n",
    "            non_trainable_params += param.numel()\n",
    "        total_params += param.numel()\n",
    "\n",
    "        layer_num += 1\n",
    "        layer_name = name.split('.')[0]\n",
    "        output_shape = list(param.size())\n",
    "\n",
    "        print(f\"{layer_num:3d} {layer_name:<34s}{str(output_shape):28s}{param.numel():10d}\")\n",
    "\n",
    "    print(\"_______________________________________________________________________________\")\n",
    "    print(\"Total parameters =\", total_params)\n",
    "    print(\"Trainable parameters =\", trainable_params)\n",
    "    print(\"Non-trainable parameters =\", non_trainable_params)\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    \n",
    "    \n",
    "    input_size = (1, 14, 14)  # Example input size\n",
    "    \n",
    "    print(\"Input Size (MB):\", input_size[0] * input_size[1] * input_size[2] * 4 / (1024 * 1024))\n",
    "    print(\"Forward/Backward pass size (MB):\", 2 * trainable_params * 4 / (1024 * 1024))\n",
    "    print(\"Param Size (MB):\", total_params * 4 / (1024 * 1024))\n",
    "    print(\"Estimated Total Size (MB) :\", (input_size[0] * input_size[1] * input_size[2] + 2 * trainable_params + total_params) * 4 / (1024 * 1024))\n",
    "\n",
    "print_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_reshape_uint8 = torch.load(\"xtrain2500001414reshapeduint8s3.pth\")\n",
    "scaled_ytrain_uint8 = torch.load(\"ytrain250000reshapedint64s3.pth\")\n",
    "xval_reshape_uint8 = torch.load(\"xval441201414reshapeduint8s3.pth\" )\n",
    "scaled_yval_uint8 = torch.load(\"yval44120reshapedint64s3.pth\")\n",
    "xtest_reshape_uint8 = torch.load(\"xtest452701414reshapeduint8s3.pth\")\n",
    "scaled_ytest_uint8 = torch.load(\"ytest45270reshapedint64s3.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X.unsqueeze(1)\n",
    "        self.y = y\n",
    "        self.len = self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    \n",
    "batch_size = 503\n",
    "#Just for wast training making batch_size = 100\n",
    "#batch_size = 2500\n",
    "\n",
    "#\n",
    "\n",
    "# Instantiate training and test data\n",
    "train_data = Data(xtrain_reshape_uint8, scaled_ytrain_uint8)\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_data = Data(xval_reshape_uint8, scaled_yval_uint8)\n",
    "val_dataloader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_data = Data(xtest_reshape_uint8, scaled_ytest_uint8)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# # Check it's working\n",
    "# for batch, (X, y) in enumerate(train_dataloader):\n",
    "#     print(f\"Batch: {batch+1}\")\n",
    "#     print(f\"XTrain shape: {X.shape}\")\n",
    "#     print(f\"yTrain shape: {y.shape}\")\n",
    "#     break\n",
    "# for batch, (X, y) in enumerate(val_dataloader):\n",
    "#     print(f\"Batch: {batch+1}\")\n",
    "#     print(f\"XVal: {X.shape}\")\n",
    "#     print(f\"yVal: {y.shape}\")\n",
    "#     break\n",
    "# for batch, (X, y) in enumerate(test_dataloader):\n",
    "#     print(f\"Batch: {batch+1}\")\n",
    "#     print(f\"XTest: {X.shape}\")\n",
    "#     print(f\"yTest: {y.shape}\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorchtrainer as ptt\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "trainer = ptt.create_default_trainer(model, optimizer, criterion, verbose=1)\n",
    "trainer.register_post_iteration_callback(ptt.callback.ValidationCallback(val_dataloader, metric=ptt.metric.TorchLoss(criterion)), frequency=200)\n",
    "validation_callback = ptt.callback.ValidationCallback(val_dataloader, metric=ptt.metric.TorchLoss(criterion))\n",
    "trainer.register_post_epoch_callback(validation_callback, frequency=1)\n",
    "accuracy_callback = ptt.callback.MetricCallback(metric=ptt.metric.Accuracy(prediction_transform=lambda x: x.argmax(dim=1, keepdim=False)))\n",
    "trainer.register_post_iteration_callback(accuracy_callback, frequency=1)\n",
    "trainer.add_progressbar_metric(\"validation loss %.4f | accuracy %.4f\", [validation_callback, accuracy_callback])\n",
    "\n",
    "trainer.train(train_dataloader, max_epochs=2) #max_epochs=15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'pretrainedWeights_E71.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inference(model, test_dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    loss, total, correct = 0.0, 0.0, 0.0\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    for batch_idx, (xtest, ytest) in enumerate(test_dataloader):\n",
    "        xtest, ytest = xtest.to(device), ytest.to(device)\n",
    "        # Inference\n",
    "        outputs = model(xtest)\n",
    "        batch_loss = criterion(outputs, ytest)\n",
    "        loss += batch_loss.item()\n",
    "        # Prediction\n",
    "        #print(outputs)\n",
    "        _, pred_labels = torch.max(outputs, 1)\n",
    "        pred_labels = pred_labels.view(-1)\n",
    "        correct += torch.sum(torch.eq(pred_labels, ytest)).item()\n",
    "        total += len(ytest)\n",
    "\n",
    "    accuracy = correct/total\n",
    "    loss = loss/total\n",
    "    return accuracy, loss\n",
    "\n",
    "#%time test_inference(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brevitas.onnx as bo\n",
    "\n",
    "model.load_state_dict(torch.load('pretrainedWeights_E71.pth', map_location=torch.device('cpu')))\n",
    "bo.export_finn_onnx(model, (1, 1, 14, 14), \"DPFL_AIAccel12_export.onnx\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from finn.util.visualization import showInNetron\n",
    "from finn.util.test import get_test_model_trained\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "\n",
    "model = ModelWrapper(\"DPFL_AIAccel12_export.onnx\")\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model.save(\"DPFL_AIAccel12_tidy.onnx\")\n",
    "\n",
    "showInNetron(\"DPFL_AIAccel12_tidy.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.pytorch import ToTensor\n",
    "from qonnx.transformation.merge_onnx_models import MergeONNXModels\n",
    "from qonnx.core.datatype import DataType\n",
    "\n",
    "model = ModelWrapper(\"DPFL_AIAccel12_tidy.onnx\")\n",
    "global_inp_name = model.graph.input[0].name\n",
    "ishape = model.get_tensor_shape(global_inp_name)\n",
    "\n",
    "model.set_tensor_datatype(global_inp_name, DataType[\"UINT8\"])\n",
    "\n",
    "model.save(\"DPFL_AIAccel12_preproc2.onnx\")\n",
    "showInNetron(\"DPFL_AIAccel12_preproc2.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.insert_topk import InsertTopK\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "\n",
    "model = model.transform(InsertTopK(k=1))\n",
    "chkpt_name = \"DPFL_AIAccel12_pre_post.onnx\"\n",
    "# tidy-up again\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(InferDataTypes())\n",
    "model.save(chkpt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showInNetron(\"DPFL_AIAccel12_pre_post.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.streamline import Streamline\n",
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from qonnx.transformation.bipolar_to_xnor import ConvertBipolarMatMulToXnorPopcount\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.transformation.streamline.reorder import MakeMaxPoolNHWC, MoveScalarLinearPastInvariants\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "from qonnx.transformation.general import RemoveUnusedTensors\n",
    "\n",
    "model = ModelWrapper(\"DPFL_AIAccel12_pre_post.onnx\")\n",
    "model = model.transform(MoveScalarLinearPastInvariants())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "\n",
    "\n",
    "model = model.transform(MakeMaxPoolNHWC())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(ConvertBipolarMatMulToXnorPopcount())\n",
    "model = model.transform(Streamline())\n",
    "# absorb final add-mul nodes into TopK\n",
    "model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())\n",
    "model.save(\"DPFL_AIAccel12_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showInNetron(\"DPFL_AIAccel12_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.transformation.fpgadataflow.convert_to_hls_layers as to_hls\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import (\n",
    "    CreateDataflowPartition,\n",
    ")\n",
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten\n",
    "from qonnx.custom_op.registry import getCustomOp\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "\n",
    "# choose the memory mode for the MVTU units, decoupled or const\n",
    "mem_mode = \"decoupled\"\n",
    "\n",
    "model = ModelWrapper(\"DPFL_AIAccel12_streamlined.onnx\")\n",
    "model = model.transform(to_hls.InferBinaryMatrixVectorActivation(mem_mode))\n",
    "model = model.transform(to_hls.InferQuantizedMatrixVectorActivation(mem_mode))\n",
    "# TopK to LabelSelect\n",
    "model = model.transform(to_hls.InferLabelSelectLayer())\n",
    "# input quantization (if any) to standalone thresholding\n",
    "model = model.transform(to_hls.InferThresholdingLayer())\n",
    "model = model.transform(to_hls.InferConvInpGen())\n",
    "model = model.transform(to_hls.InferStreamingMaxPool())\n",
    "# get rid of Reshape(-1, 1) operation between hlslib nodes\n",
    "model = model.transform(RemoveCNVtoFCFlatten())\n",
    "# get rid of Tranpose -> Tranpose identity seq\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "# infer tensor data layouts\n",
    "model = model.transform(InferDataLayouts())\n",
    "\n",
    "model = model.transform(MakeMaxPoolNHWC())\n",
    "model = model.transform(to_hls.InferStreamingMaxPool())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "model = model.transform(to_hls.InferStreamingMaxPool())\n",
    "\n",
    "\n",
    "\n",
    "parent_model = model.transform(CreateDataflowPartition())\n",
    "parent_model.save(\"DPFL_AIAccel12_dataflow_parent.onnx\")\n",
    "sdp_node = parent_model.get_nodes_by_op_type(\"StreamingDataflowPartition\")[0]\n",
    "sdp_node = getCustomOp(sdp_node)\n",
    "dataflow_model_filename = sdp_node.get_nodeattr(\"model\")\n",
    "# save the dataflow partition with a different name for easier access\n",
    "dataflow_model = ModelWrapper(dataflow_model_filename)\n",
    "dataflow_model.save(\"DPFL_AIAccel12_dataflow_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'v60qManualfifo_dataflow_parent.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f16b0280e50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "showInNetron(\"DPFL_AIAccel12_dataflow_parent.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'v60qManualfifo_dataflow_model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f1699a5aa90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(\"DPFL_AIAccel12_dataflow_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "model_file = \"DPFL_AIAccel12_dataflow_model.onnx\"\n",
    "\n",
    "rtlsim_output_dir = \"output_AI-Accel-1\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(rtlsim_output_dir):\n",
    "    shutil.rmtree(rtlsim_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "\n",
    "cfg_stitched_ip = build.DataflowBuildConfig(\n",
    "    output_dir          = rtlsim_output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    target_fps          = 1000000,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    fpga_part           = \"xczu9eg-ffvb1156-2-e\",\n",
    "    board               = \"ZCU102\",\n",
    "    shell_flow_type     = build_cfg.ShellFlowType.VIVADO_ZYNQ,\n",
    "\n",
    "    folding_config_file = \"AI-Accel1_hw_config.json\", \n",
    "    \n",
    "    steps=[\"step_apply_folding_config\",\n",
    "           \"step_generate_estimate_reports\",\n",
    "           \"step_hls_codegen\",\n",
    "           \"step_hls_ipgen\",\n",
    "           \"step_set_fifo_depths\",\n",
    "           \"step_create_stitched_ip\",\n",
    "           \"step_measure_rtlsim_performance\",\n",
    "           \"step_out_of_context_synthesis\",\n",
    "           \"step_synthesize_bitfile\",\n",
    "           \"step_make_pynq_driver\",\n",
    "           \"step_deployment_package\",\n",
    "          ],\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "        build_cfg.DataflowOutputType.RTLSIM_PERFORMANCE,\n",
    "        build_cfg.DataflowOutputType.OOC_SYNTH,\n",
    "        build_cfg.DataflowOutputType.BITFILE,\n",
    "        build_cfg.DataflowOutputType.PYNQ_DRIVER,\n",
    "        build_cfg.DataflowOutputType.DEPLOYMENT_PACKAGE]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataflow accelerator from v60qManualfifo_dataflow_model.onnx\n",
      "Intermediate outputs will be generated in /tmp/finn_dev_shakeelarkam00\n",
      "Final outputs will be generated in output_ipstitch_ooc_rtlsim_unit8v60qW\n",
      "Build log is at output_ipstitch_ooc_rtlsim_unit8v60qW/build_dataflow.log\n",
      "Running step: step_apply_folding_config [1/11]\n",
      "Running step: step_generate_estimate_reports [2/11]\n",
      "Running step: step_hls_codegen [3/11]\n",
      "Running step: step_hls_ipgen [4/11]\n",
      "Running step: step_set_fifo_depths [5/11]\n",
      "Running step: step_create_stitched_ip [6/11]\n",
      "Running step: step_measure_rtlsim_performance [7/11]\n",
      "Running step: step_out_of_context_synthesis [8/11]\n",
      "Running step: step_synthesize_bitfile [9/11]\n",
      "Running step: step_make_pynq_driver [10/11]\n",
      "Running step: step_deployment_package [11/11]\n",
      "Completed successfully\n",
      "CPU times: user 6.79 s, sys: 991 ms, total: 7.78 s\n",
      "Wall time: 43min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, cfg_stitched_ip)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
